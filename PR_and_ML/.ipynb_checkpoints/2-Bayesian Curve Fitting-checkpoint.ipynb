{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Bayes' Theorem\n",
    "We are most commonly used (and are exposed) to the so called **frequentist** interpretation of probability....\n",
    "\n",
    "Richard Cox derfived the *laws* of probability from the consideration of the quantitative rules necessary for logical consistent reasoning. His starting point was the association of a numerical value to the relative belief about the thuth of propositions such as: (a) the pandemic will end next year; (b) it will rain tomorrow ; (c) this is a fair coin; and so on. The minimum requirement for this numerical value that represents relative beliefs in the truth of propositions is that it needs to obey the *transitive* property. This is, if we believe (a) more than (b), and believe (b) more than (c), then we must necessarily believe (a) more than (c). This requirement is granted by using a real number for such degree of belief.\n",
    "\n",
    "Cox began by making two assertions. The first one is that if we specify the degree of belief in a proposition is true then we automatically specify our degree of disbelief in that proposition. The second assertion goes as follows, if we first specify how much we believe that proposition $Y$ is true, and then state how much we believe that X is true given that Y is true, then we have implicitly specified how much we believe that both X and Y are true. To work out the actual details of such relationships he appealed to the rules of Boolean logic and ordinary algebra. He found that this consistency could only be ensured if the real number which we are using to specify our degree of belief of several propositions obeyed the rules of probability:\n",
    "\n",
    "$$\\text{prob}(X|I)+ \\text{prob}(\\bar{X}|I) = 1,$$\n",
    "and \n",
    "$$\\text{prob}(X,Y|I) = \\text{prob}(X|Y,I) + \\text{prob}(Y|I),$$\n",
    "\n",
    "where we have made the probabilities conditional on $I$, to denote the relevant prior information we might have. The above identities are known as the **sum** and **product** rules of probability. Some other results can be derived from them, for instance, **Bayes' theorem**:\n",
    "\n",
    "$$\\text{prob}(X|Y,I) = \\dfrac{\\text{prob}(Y|X,I)\\text{prob}((X|I))}{\\text{prob}(Y|I)}$$\n",
    "\n",
    "is obtained by noting that the statement *both X and Y are true* is the same as *both Y and X are true* so that $\\text{prob}(Y, X |I) = \\text{prob}(X,Y|I)$, then it follows.\n",
    "\n",
    "We used Bayes' theorem in a previous notebook to try to estimate the bias in a coin. In other words, by trying to answer the question: *how fair is this coin?*. \n",
    "In notebook 1-Introduction.ipynb we stated the problem of polynomial curve fitting as an optimization problem, where the goal was to minimize the error function. The same problem (of curve fitting) can be stated in probabilistic terms, as we shall see.\n",
    "\n",
    "In general terms, the goal of this *curve-fitting* problem is to be able to make predictions about a **target** variable given some new value of the input variable $\\mathbf{x}$ on the basis of a set of training data with $N$ input samples $mathbf{X}= (x_1, \\dots, x_N)^T$ and $N$ target values $\\mathbf{t} = (t_1, \\dots, t_N)^T$. As in the case of the *'strange coin'*, we can express our uncertainty about the value of the target variable using a probability distribution. We could, for instance, assume that given the value of the input variable $\\mathbf{x}$ the corresponding value of $t$ has a Gaussian distribution with mean equal to the value of:\n",
    "$$y(x, \\mathbf{w}) = \\sum_{i}^{N}w_ix^i.$$\n",
    "Thus the probability distribution is:\n",
    "$$p(t|x, \\mathbf{w}, \\beta) = \\mathcal{N}(t|y(x,\\mathbf{w}), \\beta^{-1}).$$\n",
    "\n",
    "The idea is to use the training data $\\{\\mathbf{X}, \\mathbf{t}\\}$ to determine the values of the unknown parameters $\\mathbf{w}$ and $\\beta$ by maximizing the likelihood function. Assuming data to be iid, then the likelihood function is given by:\n",
    "\n",
    "$$p(\\mathbf{t}| \\mathbf{X}, \\mathbf{w}, \\beta) = \\prod_{i=1}^{N}\\mathcal{N}\\left(t_i|y(x_i, \\vec{w}), \\beta^{-1}\\right)$$.\n",
    "\n",
    "We will work with the logarithm of the above function for a matter of convenience, then the **log likelihood** function is:\n",
    "$$\\ln p(\\mathbf{t}|\\mathbf{X}, \\mathbf{w}, \\beta) = -\\dfrac{\\beta}{2}\\sum_{i}^{N}\\left[t_i- y(x_i, \\vec(w))\\right]^2 +\\dfrac{N}{2}\\ln \\beta - \\dfrac{N}{2}\\ln(2\\pi).$$\n",
    "\n",
    "To determine the maximum likelihood solution for the estimation of the polynomial coefficients $\\vec{w}_{ML}$ we need to maximize the above function with respect to $\\vec{w}$. Note that the last two terms are not functions of $\\vec{w}$ and they won't survive the derivative. Also, the scaling factor in front of the first term does not affect the position of the maximum with respect to $\\vec{w}$. Furthermore, instead of maximizing the log likelihood function we can minimize the negative log likelihood. Note that in the end, maximizing the likelihood is equivalent to minimizing the sum of sqaures error function we dealt with in notebook 1. The *sum-of-squares* error function has apperead as a consequence of maximizing the likelihood function under the assumption that the likelihood follows a Gaussian distribution.\n",
    "\n",
    "The parameter $\\beta$ can be estimated by maximizing the likelihood function as well, in this case, with respect to $\\beta$, which yields:\n",
    "$$\\dfrac{1}{\\beta_{ML}} = \\dfrac{1}{N}\\sum_{i= 1}^N \\left(t_i - y(x_i, \\mathbf{w}) \\right)^2.$$\n",
    "\n",
    "Once the parameters $\\vec{w}_{ML}$ are determined, we can use them to estimate $\\beta_{ML}$. Having these values, we can now make predictions for new samples of the input variable $x$, we have a probabilistic model. This model is expressed in terms of the *predictive distribution*, that gives the probability distribution over $t$, rather than simply a point estimate. \n",
    "\n",
    "$$p(t|x, \\mathbf{w}_{ML}, \\beta_{ML}) = \\mathcal{N}\\left(t | y(x, \\mathbf{w}_{ML}), \\beta_{ML}^{-1}\\right).$$\n",
    "\n",
    "Up to this point we haven't made any assumption about our prior knowledge of the polynomial coefficients $\\vec{w}$. We could, for instance, assume they are iid from a Gaussian distribution of the form\n",
    "$$p(\\mathbf{w}|\\alpha) = \\mathcal{N}\\left(\\mathbf{w}|\\mathbf{0}, \\alpha^{-1} \\mathbf{I}\\right) = \\left(\\dfrac{\\alpha}{2\\pi}\\right)^{(M+1)/2}\\exp \\left\\{-\\dfrac{\\alpha}{2}\\mathbf{w}^T\\mathbf{w}\\right\\},$$\n",
    "where $\\alpha$ is the (so-called) *precision* of the distribution, and $M+1$ is the number of parameters in a $M$ dimensional vector $\\mathbf{w}$ for an Mth order polynomial. Now that we have a prior distribution for the poynomial coefficients, we can use Bayes' theorem to estimate the posterior distribution for $\\mathbf{w}$ which is proportional to the product of the prior and the likelihood function\n",
    "$$p(\\mathbf{w}|\\mathbf{X}, \\mathbf{t}, \\alpha, \\beta) \\propto p(\\mathbf{t}|\\mathbf{X}, \\mathbf{w}, \\beta)p(\\mathbf{w}|\\alpha).$$\n",
    "\n",
    "Having the posterior at hand allows us to determine $\\mathbf{w}$ by finding the most probable value of $\\mathbf{w}$ given the data, by maximiing the posterior distribution. This technique is called *maximum posterior* or *MAP*. It is straightforward to show that maximizing the posterior distribution is equivalent to minimizing \n",
    "$$\\dfrac{\\beta}{2}\\sum_{n=1}^{N}\\left[y(x_i, \\mathbf{w}- t_i)\\right]^2+ \\dfrac{\\alpha}{2}\\mathbf{w}^T\\mathbf{w}.$$\n",
    "Thus, we see that maximizing the posterior distribution is equivalent to minimizing the **regularized** sum-of-squares error function with a regularization parameter $\\lambda = \\alpha/\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
