{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Parameter estimation is a common data analysis problem. We can think of many *real life* examples of experiments where we are interested in knowing the value of a set of parameters, e.g., the charge of the electron, the mass of the Moon, etc. In this notebook we focus on examples where we are interested in estimating the value of a single parameter. These examples will be used to discuss about the use of Bayes' Theorem, error-bars, and confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Fair coin?\n",
    "Assume that we encounter a very *strange* coin. This is, we observe that from 11 flips only 4 of them landed heads. Naturally we can ask: is this a fair coin?\n",
    "Where by fair we mean a coin that has $1/2$ chances of landing heads/tails on a flip.\n",
    "\n",
    "Moreover, let's say we determine the coin is fair. How sure are we of our assertion about the coin? IF the coin was not fair, how unfair do we think the coin is?\n",
    "\n",
    "To try answering these questions we need to formulate the problem more precisely. Instead of considering a pair of hypothesis (the coin is fair or not) we can see the problem through a large number of contiguous propositions, or hypothesis, about the range in which the *bias-weighting* of the coin might lie. Let $H$ denote this *bias-weighting*, then if $H=0$ the coin will always land tails after a flip. Conversely, when $H=1$ the coin will always land heads after a flip. Notice that $H=1/2$ indicates a **fair coin**.\n",
    "\n",
    "The propositions then could be stated in the form: \n",
    "* $0.00 < H < 0.01$;\n",
    "* $0.01 < H < 0.02$;\n",
    "* $0.03 < H < 0.03$;\n",
    "* so on...\n",
    "\n",
    "In this way, the *state of knowledge* about the (degree of) fairness or unfairness of the coin is specified by how much we believe the statement to be true, given by the probability assigned to each of the propositions or to groups of them. \n",
    "\n",
    "In the presence of data, our inference about the fairness of the coin is summarized by the contditional pdf: $$\\text{prob}(H| \\text{\\{data\\}}, I),$$ where the probability that $H$ lies within an infinitesimal interval $dH$ is given by:\n",
    "$$\\text{prob}(H| \\text{\\{data\\}}, I)dH.$$\n",
    "To estimate this posterior pdf we need to use Bayes' Theorem:\n",
    "$$\\text{prob}(X | Y,I) = \\dfrac{\\text{prob}(Y | X, I)\\times\\text{prob}(Y | I)}{\\text{prob}(Y | I)}.$$\n",
    "\n",
    "Which in our case reads:\n",
    "$$\\text{prob}(H | \\text{\\{data\\}},I) \\propto \\text{prob}(\\text{\\{data\\}}| H,I)\\times \\text{prob}(H | I),$$\n",
    "\n",
    "note that we have omitted $\\text{prob}(\\text{\\{data\\}}, I)$ since does not involve $H$. If needed, we can calculate the normalization factor from:\n",
    "$$\\int_{0}^{1}\\text{prob}(H | \\text{\\{data\\}}, I)dH = 1.$$\n",
    "\n",
    "The prior pdf, $\\text{prob}(H | I)$ represents our knowledge about the coin given the information we have about the problem: *a strange coin*. We can assign a simple probability that reflects this situation, for instance:\n",
    "$$\\text{prob}(H|I) = \\left\\{ \\begin{array}\\\\ 1, \\,\\, 0 \\leq H \\leq 1 \\\\\n",
    "                                0, \\text{ otherwise}\\end{array}\\right.$$\n",
    "                                \n",
    "This prior state of knowledge will be updated by data via the likelihood function: $\\text{prob}(\\text{\\{data\\}}| H, I)$. Additionally, we can assume the coin tosses are independent events, then the probability of getting **R heads in N tosses** is given by the binomial distribution:\n",
    "$$\\text{prob}(\\text{\\{data\\}}| H, I) = H^R(1-H)^{N-R}.$$\n",
    "\n",
    "Don't worry about the origin of this expression for the moment, we will come back to it on future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Let"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
