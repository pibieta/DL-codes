{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pibieta/DL-codes/blob/master/RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "G-h4OEtvHNKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "Kw-dJMkRHanz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "99d771ef-e6be-4bcd-cf81-d3f494cf66fd"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2018-12-28 00:01:47--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-28 00:01:47 (31.9 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "wlPLCToEHNKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eeaf6819-eee6-4c57-aa6b-70471f7fd6de"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "IBGIjGekHNKk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "ica-EmFzHNKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "80m23faQHNKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "78546013-a2fd-4705-db35-996b7dae9b0a"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "Xez4TYBUHNKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "e80bbecc-fb63-40cf-f40a-77be309831dc"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5d4c6964e0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tOV2hWzkHNK0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "id": "tV-EzyVrIQQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "4ca413d0-111a-41d5-a62f-d20b495f5963"
      },
      "cell_type": "code",
      "source": [
        "unique = list(set(names))\n",
        "for x in unique[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Kristine\n",
            " Magna\n",
            " Kristal\n",
            " Harvey\n",
            " Janka\n",
            " Millie\n",
            " Claretta\n",
            " Andreana\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3SXYym6TNnRi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nom = [x.split() for x in unique]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84SzGxycOAyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count = []\n",
        "for i in range(len(unique)):\n",
        "  count.extend(list(unique[i]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KiVmI-2ZUi7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1025
        },
        "outputId": "92db409c-2936-4ce4-8561-589029d08831"
      },
      "cell_type": "code",
      "source": [
        "[x for x in list(set(count))] + [pad_token] "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " 'E',\n",
              " 'g',\n",
              " 'j',\n",
              " 'Y',\n",
              " '-',\n",
              " 'L',\n",
              " 'P',\n",
              " 'r',\n",
              " 'I',\n",
              " 'Q',\n",
              " 'M',\n",
              " 'R',\n",
              " 'c',\n",
              " 'N',\n",
              " 'l',\n",
              " 'b',\n",
              " 'U',\n",
              " \"'\",\n",
              " 'q',\n",
              " 'Z',\n",
              " 'W',\n",
              " 'S',\n",
              " 'u',\n",
              " 'w',\n",
              " 'H',\n",
              " 'X',\n",
              " 'x',\n",
              " 'A',\n",
              " 'i',\n",
              " 'd',\n",
              " 'B',\n",
              " 'V',\n",
              " 'o',\n",
              " 'a',\n",
              " 'n',\n",
              " 'F',\n",
              " 'f',\n",
              " 'z',\n",
              " 'G',\n",
              " 'e',\n",
              " 'm',\n",
              " 'J',\n",
              " 'y',\n",
              " 'T',\n",
              " 'h',\n",
              " 's',\n",
              " 'K',\n",
              " 't',\n",
              " 'C',\n",
              " 'k',\n",
              " 'p',\n",
              " 'O',\n",
              " 'D',\n",
              " 'v',\n",
              " '#']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "YqqOptGAHNK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "13a4e2d4-5a4f-45c0-921e-1ecc8970b90b"
      },
      "cell_type": "code",
      "source": [
        "tokens = [x for x in list(set(count))] + [pad_token] ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mrElV76jHNK6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "w7uf7zdBHNLA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id = {tokens[i]: i for i in range(len(tokens))} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "G5g2NLfpHNLF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "HmAzmjJEHNLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "df0231d3-1e3d-4ab6-adea-62cbe1914db1"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 0 28 16 34  2 34 40 15 55]\n",
            " [ 0 39 15 33  8 43 55 55 55]\n",
            " [ 0  7  8 29 46 46 29 40 55]\n",
            " [ 0 39 29 33 54 34 35 35 40]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dQj2iMBSHNLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "azh_Pb_JHNLQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "j0exnikaHNLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation = 'tanh')### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation = 'softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NFZuOMS5HNLZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "3lC-jv3AHNLa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t])### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F63QVbYHHNLe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "kfQG85PYHNLg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4slhWQpbHNLk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "hKowwkM-HNLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eOeR6umIHNLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "Gg1UkEE2HNLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(tf.nn.softmax(predictions_matrix),answers_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFLlXJSlHNLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "pTL1Cf4ZHNLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "38ec73a4-ca50-454e-978b-9ed142a1b274"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(200):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5d440de2e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "T7fT0PhiHNL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "sBONj5IIHNMA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "wB97BWucHNMF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "9iFMU3JJHNMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "b5b87dcf-b606-4354-8911-348d90bf05ad"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " oa\n",
            " iarr\n",
            " aGn\n",
            " Vll\n",
            " Hlal\n",
            " vrai\n",
            " Lie\n",
            " Nel\n",
            " Gyoi\n",
            " Dr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "tI-EDZiqHNMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ab66afcc-353b-4b4a-87b9-e27c6e589451"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trump\n",
            " Trump\n",
            " Trump\n",
            " Trump\n",
            " Trump\n",
            " Trump\n",
            " Trump\n",
            " Trump\n",
            " Trump\n",
            " Trump\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B2d4iolRHNMV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "E7dGe8wiHNMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"w1gipupKtbMfs5tH\"\n",
        "COURSERA_EMAIL = \"lil.titus@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "dS6ha9hOHNMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3e5f4bf3-ed79-47f8-8e26-8be391d86a88"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)w1gipupKtbMfs5tH\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NIRZ8T22HNMc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Co6d2xOXHNMe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "rb2xbZ3bHNMe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XfEnwHeHNMi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "_I6Xxu_aHNMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "pvb1Yx2hHNMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}